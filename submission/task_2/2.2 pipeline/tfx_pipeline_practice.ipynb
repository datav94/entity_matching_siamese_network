{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Resolver got non-BaseChannel argument instance_name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3300\\1694056983.py\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# ResolverNode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m latest_model_resolver = Resolver(\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0minstance_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latest_model_resolver'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mresolver_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdsl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLatestBlessedModelStrategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\VIRAL LAPTOP\\ds_challenge\\ds_chall_env_alpas\\lib\\site-packages\\tfx\\dsl\\components\\common\\resolver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, strategy_class, config, **channels)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minput_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchannels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_types\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseChannel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Resolver got non-BaseChannel argument {input_key}.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategy_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Resolver got non-BaseChannel argument instance_name."
     ]
    }
   ],
   "source": [
    "# TODO: The components below Trainer need to be examined again\n",
    "\n",
    "\"\"\"\n",
    "Running this pipeline will recreate the errors as rising\n",
    "by Resolver node that needs to be corrected for the Channel\n",
    "\n",
    "The pipeline run has be checked until transform to be \n",
    "running as required.\n",
    "\n",
    "The trainer component lacks dimensional linkage that needs\n",
    "to be cleared at the LSTM layer input from the embedding\n",
    "Input.\n",
    "\n",
    "The model run in local env using jupyter can be seen in \n",
    "entity_matching.ipynb\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import tfx\n",
    "import tensorflow as tf\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import Transform\n",
    "from tfx.v1.dsl import Resolver\n",
    "from tfx.v1.orchestration import LocalDagRunner\n",
    "from tfx.v1.types.standard_artifacts import Model, ModelBlessing\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.v1.proto import Output, SplitConfig\n",
    "from tfx.proto import trainer_pb2\n",
    "\n",
    "_MODULE_FILE = \"../ds_challenge/transform.py\"\n",
    "TRAINING_STEPS = 1000\n",
    "EVALUATION_STEPS = 100\n",
    "_pipeline_root = \"../ds_challenge/tfx_pipeline\"\n",
    "trainer_file = \"../ds_challenge/module.py\"\n",
    "_INPUT_DATA_DIR = \"../ds_challenge/data\"\n",
    "_serving_model_dir = os.path.join(_pipeline_root, 'serving_model')\n",
    "_serving_model_dir_lite = os.path.join(_pipeline_root, 'serving_model_lite')\n",
    "\n",
    "# Setup the DAG\n",
    "context = LocalDagRunner()._configure_context(pipeline_name=\"entity_matching_pipeline\")\n",
    "\n",
    "with context:\n",
    "\n",
    "    # Define split strategy\n",
    "    output = Output(\n",
    "        split_config = SplitConfig(\n",
    "            splits=[\n",
    "                SplitConfig.Split(name=\"train\", hash_buckets=6),\n",
    "                SplitConfig.Split(name=\"eval\", hash_buckets=2),\n",
    "                SplitConfig.Split(name=\"test\", hash_buckets=2),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    example_gen = CsvExampleGen(\n",
    "    input_base=os.path.join(os.getcwd(), _INPUT_DATA_DIR),\n",
    "    output_config=output\n",
    "    )\n",
    "\n",
    "    # Statistics Generator\n",
    "    statistics_gen = StatisticsGen(\n",
    "        examples=example_gen.outputs['examples']\n",
    "    )\n",
    "\n",
    "    # Schema Generator\n",
    "    schema_gen = SchemaGen(\n",
    "        statistics=statistics_gen.outputs[\"statistics\"],\n",
    "        infer_feature_shape=True\n",
    "    )\n",
    "\n",
    "    # Example Validator\n",
    "    example_validator = ExampleValidator(\n",
    "        statistics=statistics_gen.outputs[\"statistics\"],\n",
    "        schema=schema_gen.outputs[\"schema\"]\n",
    "    )\n",
    "\n",
    "    # Tensorflow Transform Component\n",
    "    transform = Transform(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        module_file=_MODULE_FILE\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = tfx.components.Trainer(\n",
    "        module_file=trainer_file,\n",
    "        examples=transform.outputs['transformed_examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        transform_graph=transform.outputs['transform_graph'],\n",
    "        train_args=trainer_pb2.TrainArgs(num_steps=TRAINING_STEPS),\n",
    "        eval_args=trainer_pb2.EvalArgs(num_steps=EVALUATION_STEPS)\n",
    "    )\n",
    "\n",
    "    # Model Resolver\n",
    "    model_resolver = Resolver(\n",
    "        instance_name=\"latest_blessed_model_resolver\",\n",
    "        strategy_class=tfx.v1.dsl.experimental.LatestBlessedModelStrategy,\n",
    "        model=tfx.v1.dsl.Channel(type=Model),\n",
    "        model_blessing=tfx.v1.dsl.Channel(type=ModelBlessing))\n",
    "\n",
    "    # Setup the serving components\n",
    "    infra_validator = tfx.components.InfraValidator(\n",
    "        model=trainer.outputs['model'],\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        serving_spec=tfx.proto.serving_pb2.InfraValidatorSpec(),\n",
    "        instance_name=\"infra_validator\")\n",
    "\n",
    "    pusher = tfx.components.Pusher(\n",
    "        model=trainer.outputs['model'],\n",
    "        infra_blessing=infra_validator.outputs['blessing'],\n",
    "        push_destination=tfx.proto.pusher_pb2.PushDestination(\n",
    "            filesystem=tfx.proto.pusher_pb2.PushDestination.Filesystem(\n",
    "                base_directory=_serving_model_dir)),\n",
    "        instance_name=\"pusher\")\n",
    "\n",
    "# Run the pipeline\n",
    "LocalDagRunner().run(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_alpas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
